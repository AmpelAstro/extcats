{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add external catalog for source matching:\n",
    "\n",
    "This notebook demonstrate how to add different types of astronomical catalogs into a NoSql database for later use. The process of adding an external catalog has the following steps:\n",
    "\n",
    "1. **Ingestion**: a database is created containing the catalog. Indexes are built as desired.\n",
    "2. **Testing**: a few basic tests are run on the database, to measure query execution times and catch potential errors.\n",
    "3. **Documenting**: a few key information have to be added to the catalog, such as the keys and method that can be used to support queries. Description of the catalog, and references can also be added.\n",
    "\n",
    "The base class to perform these operation is the CatalogPusher class. In the following we will make some examples, trying to illustrate the basic options of the code. For this purpose will will make use of the Million Quasr Catalog (milliquas).\n",
    "\n",
    "The milliquas catalog is a compendium of ~ 2M QSOs and AGN, largely complete from the literature up to 5 August 2017. It includes data from SDSS-DR14 NBCKDE, NBCKDE-v3, XDQSO, AllWISE and Peters photometric quasar catalogs and from all-sky radio/X-ray associated objects which are calculated by the author. Each object is presented with its original name, best redshift, and 0.1-arcsecond-accurate astrometry (sourced from optical APM/USNO-B/SDSS data). Ref: https://heasarc.gsfc.nasa.gov/W3Browse/all/milliquas.html\n",
    "\n",
    "The data used for this test example notebook can be downloaded from: https://desycloud.desy.de/index.php/s/0KiEujzQ4yN1lVQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Inserting:\n",
    "\n",
    "While the CatalogPusher class provides interface to common/bulk operations, as catalogs come in a wide variety of sizes and formats, the user is requested to contribute two key functions to allow the external catalog to be parsed and ingested in the databse:\n",
    "\n",
    "* a 'reader' to parse the raw files with the catalog data into a list of dictionaries\n",
    "* a 'modifier' to edit the document of the single sources (add healpix indexes, format coordinates, remove columns, ecc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:extcats.CatalogPusher:found 1 files for catalog milliquas in data source: ['../testdata/milliquas/']\n",
      "INFO:extcats.CatalogPusher:checking raw files for existence and consistency..\n",
      "INFO:extcats.CatalogPusher:all files exists and have consistent type.\n",
      "INFO:extcats.CatalogPusher:file reader read_table assigned to pusher.\n",
      "INFO:extcats.CatalogPusher:source document modifer mqc_modifier assigned to pusher.\n",
      "INFO:extcats.CatalogPusher:using mongo client at localhost:27017\n",
      "INFO:extcats.CatalogPusher:connecting to database milliquas. Here some stats:\n",
      "INFO:extcats.CatalogPusher:{\n",
      "  \"db\": \"milliquas\",\n",
      "  \"collections\": 2,\n",
      "  \"views\": 0,\n",
      "  \"objects\": 1998468,\n",
      "  \"avgObjSize\": 470.90632974858744,\n",
      "  \"dataSize\": 941091231.0,\n",
      "  \"storageSize\": 287059968.0,\n",
      "  \"numExtents\": 0,\n",
      "  \"indexes\": 4,\n",
      "  \"indexSize\": 87138304.0,\n",
      "  \"fsUsedSize\": 194300112896.0,\n",
      "  \"fsTotalSize\": 231446335488.0,\n",
      "  \"ok\": 1.0\n",
      "}\n",
      "WARNING:extcats.CatalogPusher:collection srcs already exists and append_to_coll is False. Nothing to do.\n"
     ]
    }
   ],
   "source": [
    "from extcats import CatalogPusher\n",
    "\n",
    "# build the pusher object and point it to the raw files.\n",
    "mqp = CatalogPusher.CatalogPusher(\n",
    "    catalog_name = 'milliquas',             # short name of the catalog\n",
    "    data_source = '../testdata/milliquas/', # where to find the data\n",
    "    file_type = 'tdat.gz'\n",
    "    )\n",
    "\n",
    "\n",
    "# define the reader for the raw files. In this case the formatting or the raw file \n",
    "# is pretty ugly so we have to put quite a lot of information here.\n",
    "# the pandas package provides very efficient ways to read flat files and its use\n",
    "# is recommended. For this specific example see:\n",
    "# https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_table.html\n",
    "catcols=['name', 'ra', 'dec', 'lii', 'bii', 'broad_type', 'rmag', \n",
    "         'bmag', 'optical_flag', 'red_psf_flag', 'blue_psf_flag',\n",
    "         'redshift', 'ref_name', 'ref_redshift', 'qso_prob', \n",
    "         'radio_name', 'xray_name', 'alt_name_1', 'alt_name_2', 'class']\n",
    "import pandas as pd\n",
    "mqp.assign_file_reader(\n",
    "        reader_func = pd.read_table,         # callable to use to read the raw_files. \n",
    "        read_chunks = True,                  # weather or not the reader process each file into smaller chunks.\n",
    "        names=catcols,                       # All other arguments are passed directly to this function.\n",
    "        chunksize=50000,\n",
    "        engine='c',\n",
    "        skiprows=65,\n",
    "        sep='|',\n",
    "        index_col=False,\n",
    "        comment='<')\n",
    "\n",
    "\n",
    "# now we have to define a modifier function that acts on the single documents\n",
    "# (dictionaries) and format them in the way they have to appear in the database.\n",
    "# in this case we format coordinates in the geoJSON type (this enables mongo to\n",
    "# support queries in spherical cooridnates), and we assign to each source its\n",
    "# healpix index on a grid of order 16, corresponding to ~3\" resolution.\n",
    "from healpy import ang2pix\n",
    "def mqc_modifier(srcdict):\n",
    "    \n",
    "    # format coordinates into geoJSON type (commented version uses 'legacy' pair):\n",
    "    # unfortunately mongo needs the RA to be folded into -180, +180\n",
    "    ra=srcdict['ra'] if srcdict['ra']<180. else srcdict['ra']-360.\n",
    "    srcdict['pos']={\n",
    "            'type': 'Point', \n",
    "            'coordinates': [ra, srcdict['dec']]\n",
    "                    }\n",
    "    #srcdict['pos']=[srcdict['ra'], srcdict['dec']] # This is the legacy coordinate format\n",
    "    \n",
    "    # add healpix index\n",
    "    srcdict['hpxid_16']=int(\n",
    "        ang2pix(2**16, srcdict['ra'], srcdict['dec'], lonlat = True, nest = True))\n",
    "    \n",
    "    return srcdict\n",
    "\n",
    "mqp.assign_dict_modifier(mqc_modifier)\n",
    "\n",
    "# fill in the database, creting indexes on the position and healpix ID.\n",
    "import pymongo\n",
    "mqp.push_to_db(\n",
    "    coll_name = 'srcs', \n",
    "    index_on = ['hpxid_16', [('pos', pymongo.GEOSPHERE)] ] ,\n",
    "    index_args = [{}, {}], # specify arguments for the index creation\n",
    "    overwrite_coll = False, \n",
    "    append_to_coll = False)\n",
    "\n",
    "# now print some info on the database\n",
    "#mqp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Testing the catalog\n",
    "\n",
    "At this stage, a simple test is run on the database, consisting in crossmatching with a set of randomly distributed points. The query time is also measured, allowing to decide on the indexing strategy and query functions.\n",
    "\n",
    "The _run_test_ method of the CatalogPusher object provides convenient way to test a user defined query function on a set of uniformly ditributed points on a sphere. Standard query functions are defined in the CatalogQuery module. They are decribed in the _query_example_ notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:extcats.CatalogPusher:running test queries using 1000 random points\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1835.14it/s]\n",
      "INFO:extcats.CatalogPusher:Total document found for query: 0\n",
      "INFO:extcats.CatalogPusher:Took 5.46e-01 sec for 1000 random queries. Average query time: 5.463e-04 sec\n",
      "INFO:extcats.CatalogPusher:running test queries using 1000 random points\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 2052.31it/s]\n",
      "INFO:extcats.CatalogPusher:Total document found for query: 0\n",
      "INFO:extcats.CatalogPusher:Took 4.89e-01 sec for 1000 random queries. Average query time: 4.892e-04 sec\n"
     ]
    }
   ],
   "source": [
    "# define the funtion to test coordinate based queries:\n",
    "import numpy as np\n",
    "from healpy import ang2pix, get_all_neighbours\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "from math import radians\n",
    "# define your search radius\n",
    "rs_arcsec = 10.\n",
    "\n",
    "def test_query_healpix(ra, dec, coll):\n",
    "    \"\"\"query collection for the closest point within \n",
    "    rs_arcsec of target ra, dec. It uses healpix ID\n",
    "    to perform the search.\n",
    "    \n",
    "    The results as returned as an astropy Table. \"\"\"\n",
    "    \n",
    "    # find the index of the target pixel and its neighbours \n",
    "    target_pix = int( ang2pix(2**16, ra, dec, nest = True, lonlat = True) )\n",
    "    neighbs = get_all_neighbours(2*16, ra, dec, nest = True, lonlat = True)\n",
    "\n",
    "    # remove non-existing neigbours (in case of E/W/N/S) and add center pixel\n",
    "    pix_group = [int(pix_id) for pix_id in neighbs if pix_id != -1] + [target_pix]\n",
    "    \n",
    "    # query the database for sources in these pixels\n",
    "    qfilter = { 'hpxid_16': { '$in': pix_group } }\n",
    "    qresults = [o for o in coll.find(qfilter)]\n",
    "    if len(qresults)==0:\n",
    "        return None\n",
    "    \n",
    "    # then use astropy to find the closest match\n",
    "    tab = Table(qresults)\n",
    "    target = SkyCoord(ra, dec, unit = 'deg')\n",
    "    matches_pos = SkyCoord(tab['ra'], tab['dec'], unit = 'deg')\n",
    "    d2t = target.separation(matches_pos).arcsecond\n",
    "    match_id = np.argmin(d2t)\n",
    "\n",
    "    # if it's too far away don't use it\n",
    "    if d2t[match_id]>rs_arcsec:\n",
    "        return None\n",
    "    return tab[match_id]\n",
    "\n",
    "\n",
    "def test_query_2dsphere(ra, dec, coll):\n",
    "    \"\"\"query collection for the closest point within \n",
    "    rs_arcsec of target ra, dec. It uses mondod spherical\n",
    "    geometry queries.\n",
    "    \n",
    "    The results as returned as an astropy Table. \"\"\"\n",
    "    \n",
    "    \n",
    "    # fold the RA between -180 and 180.\n",
    "    if ra > 180:\n",
    "        ra = ra - 360.\n",
    "    \n",
    "    # query and return\n",
    "    geowithin={\"$geoWithin\": { \"$centerSphere\": [[ra, dec], radians(rs_arcsec/3600.)]}}\n",
    "    qresults = [o for o in coll.find({\"pos\": geowithin})]\n",
    "    if len(qresults)==0:\n",
    "        return None\n",
    "    \n",
    "    # then use astropy to find the closest match\n",
    "    tab = Table(qresults)\n",
    "    target = SkyCoord(ra, dec, unit = 'deg')\n",
    "    matches_pos = SkyCoord(tab['ra'], tab['dec'], unit = 'deg')\n",
    "    d2t = target.separation(matches_pos).arcsecond\n",
    "    match_id = np.argmin(d2t)\n",
    "\n",
    "    # if it's too far away don't use it\n",
    "    if d2t[match_id]>rs_arcsec:\n",
    "        return None\n",
    "    return tab[match_id]\n",
    "\n",
    "# run the test. Here we compare queries based on the \n",
    "# healpix index with those based on the 2dsphere mongod support.\n",
    "mqp.run_test(test_query_healpix, npoints = 1000)\n",
    "mqp.run_test(test_query_2dsphere, npoints = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Adding metadata\n",
    "\n",
    "Once the database is set up and the query performance are satisfactory, metadata describing the catalog content, contact person, and query strategies have to be added to the catalog database. If presents, the keys and parameters for the healpix partitioning of the sources are also to be given, as well as the name of the compound geoJSON/legacy pair entry in the documents.\n",
    "\n",
    "This information will be added into the 'metadata' collection of the database which will be accessed by the CatalogQuery. The metadata will be stored in a dedicated collection so that the database containig a given catalog will have two collections:\n",
    "    - db['srcs'] : contains the sources.\n",
    "    - db['meta'] : describes the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:extcats.CatalogPusher:adding metadata for HEALPix key named: hpxid_16\n",
      "INFO:extcats.CatalogPusher:adding metadata for 2dsphere coordinates named: pos\n",
      "INFO:extcats.CatalogPusher:adding science related metadata to database.\n"
     ]
    }
   ],
   "source": [
    "mqp.healpix_meta(healpix_id_key = 'hpxid_16', order = 16, is_indexed = True, nest = True)\n",
    "mqp.sphere2d_meta(sphere2d_key = 'pos', is_indexed = True, pos_format = 'geoJSON')\n",
    "mqp.science_meta(\n",
    "    contact =  'C. Norris', \n",
    "    email = 'chuck.norris@desy.de', \n",
    "    description = 'compilation of AGN and Quasar',\n",
    "    reference = 'http://quasars.org/milliquas.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
